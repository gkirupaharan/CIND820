
#Install seaborn and scikit-learn libraries
!pip install seaborn
!pip install scikit-learn

#Answering Research Question No.1:What are the most significant risk factors for predicting the likelihood of developing diabetes?
# From the dataset, the first column, “Diabetes_012”, depicts the following:
#0 = Not diabetic
#1 = Prediabetic
#2 = Diabetic

# Import necessary libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.feature_selection import chi2

# Load the dataset
df = pd.read_csv('Diabetes Dataset.csv')

# Display the first few rows of the dataset
df.head()

# Data Cleaning
df.dropna(inplace=True)

# Correlation Analysis
correlation_matrix = df.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Chi-Square Test for categorical variables
X = df.drop('Diabetes_012', axis=1)
y = df['Diabetes_012']

# Ensure all features are non-negative for chi-square test
X = X.abs()

chi_scores = chi2(X, y)
chi2_df = pd.DataFrame({'Variable': X.columns, 'Chi2_Score': chi_scores[0], 'P_Value': chi_scores[1]})
chi2_df.sort_values(by='Chi2_Score', ascending=False, inplace=True)
chi2_df

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Logistic Regression for Feature Importance
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
log_reg = LogisticRegression(max_iter=5000)  # Increased max_iter
log_reg.fit(X_train, y_train)

# Logistic Regression Feature Importance
importance = pd.DataFrame({'Feature': X.columns, 'Importance': log_reg.coef_[0]})
importance.sort_values(by='Importance', ascending=False, inplace=True)

print("Logistic Regression Feature Importance:")
display(importance)

# Random Forest for Feature Importance
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
rf_importance = pd.DataFrame({'Feature': X.columns, 'Importance': rf.feature_importances_})
rf_importance.sort_values(by='Importance', ascending=False, inplace=True)

print("Random Forest Feature Importance:")
display(rf_importance)

# Model Evaluation
y_pred = rf.predict(X_test)
print(classification_report(y_test, y_pred))
